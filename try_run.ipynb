{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31285ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RL\n",
    "from tensorforce import Runner\n",
    "from tensorforce import Environment\n",
    "from tensorforce import Agent\n",
    "#keras\n",
    "import tensorflow as tf\n",
    "#basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#sklearn\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import Birch\n",
    "#image processing\n",
    "from skimage.future import graph\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.color import label2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "#visialization\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"Set2\")\n",
    "#skmultiflow\n",
    "from skmultiflow.trees import HoeffdingTreeClassifier\n",
    "from skmultiflow.trees import HoeffdingAdaptiveTreeClassifier\n",
    "from skmultiflow.rules import VeryFastDecisionRulesClassifier\n",
    "from skmultiflow.trees import ExtremelyFastDecisionTreeClassifier\n",
    "#scikit \n",
    "from scipy.spatial import distance_matrix\n",
    "#graph\n",
    "import networkx as nx\n",
    "#ontology\n",
    "import owlready2 as owl\n",
    "#language model\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "#other\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d519c20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/olaf/anaconda3/envs/master/lib/python3.9/site-packages/gym/envs/registration.py:505: UserWarning: \u001b[33mWARN: The environment SpaceInvaders-v4 is out of date. You should consider upgrading to version `v5` with the environment ID `ALE/SpaceInvaders-v5`.\u001b[0m\n",
      "  logger.warn(\n",
      "A.L.E: Arcade Learning Environment (version 0.7.4+069f8bd)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "def to_shape(a, shape):\n",
    "    y_, x_ = shape\n",
    "    y, x = a.shape[0:2]\n",
    "    y_pad = (y_-y)\n",
    "    x_pad = (x_-x)\n",
    "    return np.pad(a,((y_pad//2, y_pad//2 + y_pad%2), \n",
    "                     (x_pad//2, x_pad//2 + x_pad%2),\n",
    "                    (0,0)\n",
    "                    ),\n",
    "                  mode = 'constant')\n",
    "\n",
    "def visualize_objects(label_image,image):\n",
    "    # to make the background transparent, pass the value of `bg_label`,\n",
    "    # and leave `bg_color` as `None` and `kind` as `overlay`\n",
    "    image_label_overlay = label2rgb(label_image, image=image, bg_label=0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.imshow(image_label_overlay)\n",
    "\n",
    "    for region in regionprops(label_image):\n",
    "        # take regions with large enough areas\n",
    "        if region.area >= 5:\n",
    "            # draw rectangle around segmented coins\n",
    "            minr, minc, maxr, maxc = region.bbox\n",
    "            rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                      fill=False, edgecolor='red', linewidth=2)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def find_objects(image):\n",
    "    img = rgb2gray(image)\n",
    "\n",
    "    # apply threshold\n",
    "    thresh = threshold_otsu(img)\n",
    "    reg = closing(img > thresh, square(3))\n",
    "\n",
    "    # label image regions\n",
    "    label_image = label(reg)\n",
    "    \n",
    "    return label_image\n",
    "\n",
    "def find_cut_objects(image,m_h,m_w):\n",
    "    label_image=find_objects(image)\n",
    "    regions=regionprops(label_image)\n",
    "    i=len(regions)-1\n",
    "    for reg in regions:\n",
    "        minr, minc, maxr, maxc = reg.bbox\n",
    "        split_h=np.linspace(0,(maxr-minr),1+int(np.ceil((maxr-minr)/m_h))).astype(\"int\")\n",
    "        split_w=np.linspace(0,(maxc-minc),1+int(np.ceil((maxc-minc)/m_w))).astype(\"int\")\n",
    "        for x in range(int(np.ceil((maxr-minr)/m_h))):\n",
    "            for y in range(int(np.ceil((maxc-minc)/m_w))):\n",
    "                i=i+1\n",
    "                label_image[reg.slice][split_h[x]:split_h[x+1],split_w[y]:split_w[y+1]][reg.image[split_h[x]:split_h[x+1],split_w[y]:split_w[y+1]]]=i\n",
    "\n",
    "\n",
    "    regions=regionprops(label_image)\n",
    "    objects=np.array([to_shape(image[reg.slice],(m_h,m_w)) for reg in regions])\n",
    "    return label_image, objects, regions\n",
    "\n",
    "\n",
    "def regions_to_graph(regions,labels,prox=60):\n",
    "    #weighted?\n",
    "    centroids=np.array([reg.centroid for reg in regions])\n",
    "    dist=distance_matrix(centroids,centroids)\n",
    "    dist=(dist<prox)*dist\n",
    "    G = nx.from_numpy_matrix(dist)\n",
    "    lab={x:str(labels[x]) for x in range(len(centroids))}\n",
    "    nx.set_node_attributes(G, lab, \"feature\")\n",
    "    pos_x={x:centroids[x][0] for x in range(len(centroids))}\n",
    "    nx.set_node_attributes(G, pos_x, \"position_x\")\n",
    "    pos_y={x:centroids[x][1] for x in range(len(centroids))}\n",
    "    nx.set_node_attributes(G, pos_y, \"position_y\")\n",
    "    return G\n",
    "\n",
    "\n",
    "def visualize_graph(g):\n",
    "    groups = set(nx.get_node_attributes(g,'feature').values())\n",
    "    mapping = dict(zip(sorted(groups),count()))\n",
    "    nodes = g.nodes()\n",
    "    colors = [mapping[g.nodes[n]['feature']] for n in nodes]  \n",
    "    \n",
    "    pos = nx.spring_layout(g)\n",
    "    for n in nodes:\n",
    "        pos[n][1]=-1*g.nodes[n]['position_x']\n",
    "        pos[n][0]=g.nodes[n]['position_y']\n",
    "\n",
    "    ec = nx.draw_networkx_edges(g, pos, alpha=0.2)\n",
    "    nc = nx.draw_networkx_nodes(g, pos, nodelist=nodes, node_color=colors, node_size=100, cmap=plt.cm.jet)\n",
    "    plt.colorbar(nc)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def graph_to_embedding(Graphs,model,iterations=2,epochs=10,keep_train=True,rebuild_vocab=False,seed=42):\n",
    "    Doc_all=[]\n",
    "    for i in range(len(Graphs)):\n",
    "        hashes=nx.weisfeiler_lehman_subgraph_hashes(Graphs[i], iterations=iterations, node_attr=\"feature\")\n",
    "        Doc=[]\n",
    "        for node in Graphs[i].nodes:\n",
    "            Doc=Doc+[Graphs[i].nodes[node][\"feature\"]]+hashes[node]\n",
    "        \n",
    "        Doc_all=Doc_all+[Doc.copy()]\n",
    "    documents = [\n",
    "            TaggedDocument(words=doc, tags=[])\n",
    "            for i, doc in enumerate(Doc_all)\n",
    "        ]\n",
    "    \n",
    "    if rebuild_vocab:\n",
    "        if len(model.wv)>0:\n",
    "            model.build_vocab(documents,update=True)\n",
    "        else:\n",
    "            model.build_vocab(documents)\n",
    "        \n",
    "    if keep_train:\n",
    "        model.train(documents,total_examples=len(documents),epochs=epochs)\n",
    "        \n",
    "    #np.array([model.docvecs[str(i)] for i, _ in enumerate(Doc_all)])\n",
    "    model.random.seed(seed)\n",
    "    return np.array([model.infer_vector(doc) for doc in Doc_all])\n",
    "\n",
    "\n",
    "\n",
    "class CustomEnvironment(Environment):\n",
    "\n",
    "    def __init__(self, base_env):\n",
    "        self.base_env=base_env\n",
    "        self.num_clusters_obj=16\n",
    "        self.image_seg=Birch(n_clusters=None,threshold=128,branching_factor=100)\n",
    "        self.pca_obj=IncrementalPCA(n_components=50)\n",
    "        self.max_obj_width=160//10\n",
    "        self.max_obj_height=210//10\n",
    "        self.prox=40\n",
    "        self.state_param={}\n",
    "        self.state_param[\"type\"]=\"float\"\n",
    "        self.state_param[\"shape\"]=128\n",
    "        self.state_param[\"min_value\"]=-1\n",
    "        self.state_param[\"max_value\"]=1\n",
    "        self.example_objects={}\n",
    "        self.example_objects_pca={}\n",
    "        self.total_timestep=0\n",
    "        self.keep_train=True\n",
    "        self.rebuild_vocab=True\n",
    "        self.iterations=1\n",
    "        #graph list \n",
    "        self.graph_list=[]\n",
    "        #semantic model\n",
    "        self.dimensions=128\n",
    "        self.min_count=1\n",
    "        self.seed=42\n",
    "        self.workers = 4\n",
    "        self.epochs = 20\n",
    "        self.learning_rate = 0.0025\n",
    "        self.window=5\n",
    "        self.hs=1\n",
    "        self.dm=1\n",
    "        self.negative=0\n",
    "        self.semantic_model=Doc2Vec(\n",
    "            vector_size=self.dimensions,\n",
    "            window=self.window,\n",
    "            min_count=self.min_count,\n",
    "            dm=self.dm,\n",
    "            hs=self.hs,\n",
    "            negative=self.negative,\n",
    "            workers=self.workers,\n",
    "            epochs=self.epochs,\n",
    "            alpha=self.learning_rate,\n",
    "            seed=self.seed,\n",
    "            max_vocab_size=100000\n",
    "        )\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "    def states(self):\n",
    "        return self.state_param\n",
    "\n",
    "    def actions(self):\n",
    "        return self.base_env.actions()\n",
    "\n",
    "    def train_semantic(self):\n",
    "        #make embedding\n",
    "        graph_to_embedding(self.graph_list,self.semantic_model,iterations=self.iterations,epochs=self.epochs,keep_train=True,rebuild_vocab=True,seed=42)\n",
    "        \n",
    "    \n",
    "    def preprocess_state(self, state, train=False, rebuild_vocab=False, train_semantic=False):\n",
    "        \n",
    "        #cut objects\n",
    "        label_image, objects, regions=find_cut_objects(state,self.max_obj_height,self.max_obj_width)\n",
    "        X=objects.reshape(objects.shape[0],-1)\n",
    "        \n",
    "        #PCA\n",
    "        if train:\n",
    "            self.pca_obj.partial_fit(np.vstack((X,X)))\n",
    "            \n",
    "        X=self.pca_obj.transform(X)\n",
    "        \n",
    "        #BIRCH clustering\n",
    "        if train:\n",
    "            self.image_seg.partial_fit(X)\n",
    "            if self.image_seg.n_clusters is None and len(self.image_seg.subcluster_labels_)>self.num_clusters_obj-1:\n",
    "                self.image_seg.set_params(n_clusters=self.num_clusters_obj-1)\n",
    "                self.image_seg.partial_fit()\n",
    "                \n",
    "        labels=self.image_seg.predict(X)\n",
    "            \n",
    "        for i in range(len(labels)):\n",
    "            if train:\n",
    "                self.example_objects[labels[i]]=state[regions[i].slice]\n",
    "                self.example_objects_pca[labels[i]]=self.pca_obj.inverse_transform(X[i]).reshape(self.max_obj_height,self.max_obj_width,3)\n",
    "            \n",
    "            label_image[regions[i].slice][regions[i].image]=labels[i]+1\n",
    "        \n",
    "        #make graph\n",
    "        graph=regions_to_graph(regions,labels,prox=self.prox)\n",
    "        \n",
    "        #make embedding\n",
    "        embedding=graph_to_embedding([graph],self.semantic_model,iterations=self.iterations,epochs=self.epochs,keep_train=train_semantic,rebuild_vocab=rebuild_vocab,seed=42)\n",
    "        \n",
    "        #clip emmbeding\n",
    "        embedding=np.clip(embedding,self.state_param[\"min_value\"], self.state_param[\"max_value\"])[0]\n",
    "        #smaller image\n",
    "        label_image=np.max(np.dstack((label_image[0::2,0::2],label_image[1::2,1::2])),axis=-1)\n",
    "        return label_image.astype(\"int8\"),regions,labels,graph,embedding\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Optional: should only be defined if environment has a natural fixed\n",
    "    # maximum episode length; restrict training timesteps via\n",
    "    #     Environment.create(..., max_episode_timesteps=???)\n",
    "    def max_episode_timesteps(self):\n",
    "        return super().max_episode_timesteps()\n",
    "\n",
    "    # Optional additional steps to close environment\n",
    "    def close(self):\n",
    "        super().close()\n",
    "\n",
    "    def reset(self):\n",
    "        state = self.base_env.reset()\n",
    "        _,_,_,graph,state = self.preprocess_state(state, train=True, rebuild_vocab=True, train_semantic=True)\n",
    "        return state\n",
    "\n",
    "    def execute(self, actions):\n",
    "        next_state, terminal, reward = self.base_env.execute(actions)\n",
    "        \n",
    "        self.total_timestep+=1\n",
    "        if self.total_timestep<500:\n",
    "            self.keep_train=True\n",
    "        else:\n",
    "            self.keep_train=False\n",
    "        \n",
    "        if self.total_timestep%20==0:\n",
    "            self.train_semantic()\n",
    "            self.graph_list=[]\n",
    "            print(self.total_timestep)\n",
    "        \n",
    "        _,_,_,graph,next_state=self.preprocess_state(next_state,self.keep_train)\n",
    "        self.graph_list.append(graph)\n",
    "        \n",
    "        return next_state, terminal, reward\n",
    "    \n",
    "\n",
    "    \n",
    "trace=np.load(\"./record/trace-000000000.npz\")\n",
    "\n",
    "States=trace[\"states\"][0:30]\n",
    "\n",
    "Rewards=trace[\"reward\"]\n",
    "\n",
    "Actions=trace[\"actions\"]\n",
    "\n",
    "# OpenAI-Gym environment specification\n",
    "environment = Environment.create(\n",
    "       environment='gym', level='SpaceInvaders-v4',max_episode_timesteps=1000)\n",
    "\n",
    "custom=CustomEnvironment(environment)\n",
    "\n",
    "custom.preprocess_state(States[0], train=True, rebuild_vocab=True, train_semantic=True)\n",
    "\n",
    "Graphs=[]\n",
    "for state in States:\n",
    "    _,regions,labels,_,_=custom.preprocess_state(state, train=False)\n",
    "    Graphs.append(regions_to_graph(regions,labels,prox=40))\n",
    "    \n",
    "# X=graph_to_embedding(Graphs[0:2],custom.semantic_model,iterations=1,epochs=2,keep_train=True,rebuild_vocab=True)\n",
    "\n",
    "# print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8354ab96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "X=graph_to_embedding(Graphs[0:],custom.semantic_model,iterations=1,epochs=2,keep_train=True,rebuild_vocab=True)\n",
    "\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db921ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d26ed8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.5 ms, sys: 5.88 ms, total: 43.4 ms\n",
      "Wall time: 40.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time X=graph_to_embedding(Graphs[0:30],custom.semantic_model,iterations=1,epochs=2,keep_train=True,rebuild_vocab=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c63fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
